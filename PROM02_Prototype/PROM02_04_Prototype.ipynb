{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a3aa428",
   "metadata": {},
   "source": [
    "# 1. Setting up the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4427a5",
   "metadata": {},
   "source": [
    "# 1.1 Checking if the notebook was launched in the correct environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb9898d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prints the available list of environments with asterisk (*) next to the current environment\n",
    "#need to relaunch jupyter if launched in incorrect environment\n",
    "!conda env list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27d166d",
   "metadata": {},
   "source": [
    "## 1.2 Installing the required packages in the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857a0f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prints the list of installed packages in the environment\n",
    "#useful for checking versions and confirming if the packages have successfully installed\n",
    "!conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65301a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#installing the required packages\n",
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} numpy\n",
    "!conda install --yes --prefix {sys.prefix} pandas\n",
    "!conda install --yes --prefix {sys.prefix} opencv\n",
    "!conda install --yes --prefix {sys.prefix} scikit-image\n",
    "!conda install --yes --prefix {sys.prefix} scikit-learn\n",
    "!conda install -c conda-forge --yes --prefix {sys.prefix} python-sounddevice\n",
    "!conda install -c conda-forge  --yes --prefix {sys.prefix} pysoundfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b10c1a",
   "metadata": {},
   "source": [
    "## 1.3 Importing the installed packages in the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48191ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the packages in the environment for use\n",
    "\n",
    "import os #module allowing interaction with the file system\n",
    "import time #module to handle time-related tasks such as model training time etc.\n",
    "\n",
    "import numpy as np #module for added support to large, multi-dimensional arrays\n",
    "import pandas as pd #module for data manipulation and analysis \n",
    "\n",
    "import pickle #module for exporting the model\n",
    "import cv2 #real-time optimized Computer Vision library\n",
    "\n",
    "from skimage.feature import hog #module for feature descriptor method - HOG (Histogram of Oriented Gradients)\n",
    "\n",
    "from threading import Thread #module allowing for multiple threads in the program\n",
    "import sounddevice as sd #module to read/access sound files\n",
    "import soundfile as sf #module to play sound files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57af5d7",
   "metadata": {},
   "source": [
    "# 2. Defining functions for miscellaneous operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914ae711",
   "metadata": {},
   "source": [
    "## 2.1 Function to detect eye status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "37a626eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_drowsy(gray, frame, tempstat):\n",
    "    \n",
    "    #eye probabilities\n",
    "    eye_prob1 = 'N/A'\n",
    "    eye_prob2 = 'N/A'\n",
    "    \n",
    "    #initialising face cascade for face detection\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.05, minNeighbors=5, minSize=(30,30), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    \n",
    "    #checking if no face available\n",
    "    if len(faces) < 1:\n",
    "        tempstat = 'NO FACE DETECTED'\n",
    "        \n",
    "    else:\n",
    "        #for each face detected\n",
    "        for (x,y,w,h) in faces:\n",
    "            roi_color=frame[y:y+h, x:x+w]\n",
    "            roi_gray=gray[y:y+h, x:x+w]\n",
    "            \n",
    "            #show a blue box around it\n",
    "            cv2.rectangle(frame, (x,y), (x+w, y+h), (255, 0, 0), 1)\n",
    "            \n",
    "            #initialising eye cascade for eyes detection\n",
    "            eyes = eye_cascade.detectMultiScale(roi_gray, scaleFactor=1.1, minNeighbors=10, minSize=(15,15), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "            \n",
    "            #checking if no eyes available\n",
    "            if len(eyes) < 1:\n",
    "                tempstat = 'NO EYES DETECTED'\n",
    "            \n",
    "            #when there are 2 eyes\n",
    "            elif len(eyes) == 2:\n",
    "                eye1 = eyes[0]\n",
    "                eye2 = eyes[1]\n",
    "                \n",
    "                #getting coordinates for each eye\n",
    "                ex1, ey1, ew1, eh1 = eye1\n",
    "                ex2, ey2, ew2, eh2 = eye2\n",
    "\n",
    "                #show a green box around it\n",
    "                cv2.rectangle(roi_color, (ex1,ey1), (ex1+ew1, ey1+eh1), (0, 255, 0), 1)\n",
    "                cv2.rectangle(roi_color, (ex2,ey2), (ex2+ew2, ey2+eh2), (0, 255, 0), 1)    \n",
    "                \n",
    "                #extract that image\n",
    "                eye_image1 = roi_gray[ey1:ey1+eh1, ex1:ex1+ew1]\n",
    "                eye_image2 = roi_gray[ey2:ey2+eh2, ex2:ex2+ew2]\n",
    "                \n",
    "                #resize that image\n",
    "                eye_image1 = cv2.resize(eye_image1, (80,80))\n",
    "                eye_image2 = cv2.resize(eye_image2, (80,80))\n",
    "                \n",
    "                #extract features from image\n",
    "                eye_hog1 = get_hog(eye_image1)\n",
    "                eye_hog2 = get_hog(eye_image2)\n",
    "                \n",
    "                #predict eye state on those features\n",
    "                eye_pred1 = svm_hog_model.predict([eye_hog1])\n",
    "                eye_pred2 = svm_hog_model.predict([eye_hog2])\n",
    "                \n",
    "                #if both eyes are closed, show status 'EYES CLOSED'\n",
    "                if eye_pred1 == eye_pred2 == 0:\n",
    "                    tempstat = 'EYES CLOSED'\n",
    "                \n",
    "                #if both eyes are open, show status 'EYES OPEN'\n",
    "                elif eye_pred1 == eye_pred2 == 1:\n",
    "                    tempstat = 'EYES OPEN'\n",
    "                #else show 'EYES OPEN'\n",
    "                else:\n",
    "                    tempstat = 'PARTIAL DETECTION'\n",
    "                    \n",
    "                #predict probabilities for eye states on those features\n",
    "                eye_prob1 = \"%.2f\" % (round((svm_hog_model.predict_proba([eye_hog1])[:,1])[0], 4) * 100)\n",
    "                eye_prob2 = \"%.2f\" % (round((svm_hog_model.predict_proba([eye_hog2])[:,1])[0], 4) * 100)\n",
    "                \n",
    "    #display probabilities on the frame\n",
    "    cv2.putText(frame, f'LEFT EYE: {eye_prob1}', (30, 450), cv2.FONT_HERSHEY_DUPLEX, 0.5, (0, 0, 255))\n",
    "    cv2.putText(frame, f'RIGHT EYE: {eye_prob2}', (230, 450), cv2.FONT_HERSHEY_DUPLEX, 0.5, (0, 0, 255))\n",
    "    \n",
    "    #display status result on the frame\n",
    "    cv2.putText(frame, f'STATUS: {tempstat}', (30, 90), cv2.FONT_HERSHEY_DUPLEX, 0.7, (0, 0, 255))\n",
    "            \n",
    "    return tempstat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40996b26",
   "metadata": {},
   "source": [
    "## 2.2 Function for extracting HOG features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea1fb0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hog(image):\n",
    "    #getting hog features for image\n",
    "    fd, hog_image = hog(image, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True)\n",
    "    return fd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa00ad0",
   "metadata": {},
   "source": [
    "## 2.3 Function for playing alert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5331b057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sound_alert(data, fs):\n",
    "    #playing the sound file\n",
    "    sd.play(data, fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecf4404",
   "metadata": {},
   "source": [
    "# 3. Loading the required files, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8eaaaf3",
   "metadata": {},
   "source": [
    "## 3.1 Reading the model file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b4c742c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model file is located at: C:\\Users\\Sarthak\\Desktop\\Projects\\model_SVM_HOG.sav\n"
     ]
    }
   ],
   "source": [
    "#initialsing the file path for the model\n",
    "model_file_name = 'model_SVM_HOG.sav'\n",
    "model_path = f'{os.path.dirname(os.getcwd())}\\\\{model_file_name}'\n",
    "\n",
    "#printing the model file, if found\n",
    "print(f'The model file is located at: {model_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0502c1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the model file\n",
    "with open(model_path, 'rb') as file:  \n",
    "    svm_hog_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffb31ec",
   "metadata": {},
   "source": [
    "## 3.2 Haar cascade files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43b416d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Haar Cascade files for face and eye detection\n",
    "face_cascade = cv2.CascadeClassifier('files\\\\haar\\\\haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('files\\\\haar\\\\haarcascade_eye.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39c27bf",
   "metadata": {},
   "source": [
    "## 3.3 Sound file for alert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc696783",
   "metadata": {},
   "outputs": [],
   "source": [
    "#location for sound file\n",
    "alert_filename = 'files\\\\sound\\\\alert.wav'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adefb803",
   "metadata": {},
   "source": [
    "# 4. Main process flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff331167",
   "metadata": {},
   "source": [
    "## 4.1 Declaring variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baeda9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "alarm_on = False #trigger for alert\n",
    "frame_counter = 0 #counter of frames for drowsy state\n",
    "status = '' #status of eyes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a8bf18",
   "metadata": {},
   "source": [
    "## 4.2 Check if the camera works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc342008",
   "metadata": {},
   "outputs": [],
   "source": [
    "#streaming cam feed from phone\n",
    "#url, when on uni-wifi\n",
    "#url = \"http://10.108.50.88:4747/video\" \n",
    "#url, when on mobile-hotspot\n",
    "#url = \"http://10.9.149.216:4747/video\" \n",
    "#cap = cv2.VideoCapture(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b8cfd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#streaming live video from webcam\n",
    "cap = cv2.VideoCapture(-1)\n",
    "if not cap.isOpened():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    cap = cv2.VideoCapture(1)\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"ERROR: Unable to open webcam on device!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b047c9",
   "metadata": {},
   "source": [
    "## 4.3 Detecting if the driver is drowsy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fea2918e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the sound file\n",
    "data, fs = sf.read(alert_filename, dtype='float32')\n",
    "\n",
    "while True:\n",
    "    #reading video in frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    #rotating camera, when using mobile camera\n",
    "    #frame = cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    \n",
    "    #grayscaling the frame\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #checking drowsy status\n",
    "    status = detect_drowsy(gray, frame, status)\n",
    "    \n",
    "    #increment counter if eyes are closed\n",
    "    if status == 'EYES CLOSED':\n",
    "        frame_counter += 1\n",
    "        #if counter more than 50 or 4 secs\n",
    "        if frame_counter >= 50:\n",
    "            #switch the alarm\n",
    "            alarm_on = True\n",
    "            if alarm_on == True:\n",
    "                #display alert\n",
    "                cv2.putText(frame, \"DROWSINESS ALERT!\", (10, 30), cv2.FONT_HERSHEY_DUPLEX, 1, (0, 0, 255), 2)\n",
    "                #ring the alarm corresponding to the alert\n",
    "                t = Thread(target=sound_alert(data, fs))\n",
    "                t.daemon = True\n",
    "                t.start()\n",
    "                \n",
    "    #if the driver is awake\n",
    "    elif status == 'EYES OPEN':\n",
    "        #reset the alarm and frame counter\n",
    "        frame_counter = 0\n",
    "        alarm_on = False    \n",
    "    \n",
    "    cv2.imshow('Drowsiness Detector', frame)\n",
    "    #exit on pressing 'q'\n",
    "    if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
